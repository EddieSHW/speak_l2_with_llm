import gradio as gr
from src.config.settings import MODEL_NAME, DEFAULT_TEMPERATURE, DEFAULT_MAX_TOKENS
from src.services.ollama_service import OllamaService
from src.utils.audio_utils import AudioUtils

class ChatInterface:
    """ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.ollama_service = OllamaService()
        self.audio_utils = AudioUtils()
        
    def chat(self, message, history, temperature, max_tokens, model):
        """ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã«ã‚ˆã‚‹ãƒãƒ£ãƒƒãƒˆå‡¦ç†"""
        # Ollamaã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—
        response = self.ollama_service.get_chat_response(
            message, history, model, temperature, max_tokens
        )
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
        audio_file = self.audio_utils.text_to_speech(response)
        
        # å±¥æ­´ã‚’æ›´æ–°ã—ã¦è¿”ã™
        history.append((message, response))
        return history, history, audio_file
    
    def voice_chat(self, audio_file, history, temperature, max_tokens, model):
        """éŸ³å£°å…¥åŠ›ã«ã‚ˆã‚‹ãƒãƒ£ãƒƒãƒˆå‡¦ç†"""
        if audio_file is None:
            return history, history, None
        
        # éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        text = self.audio_utils.transcribe_audio(audio_file)
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¿œç­”ã‚’ç”Ÿæˆ
        response = self.ollama_service.get_chat_response(
            text, history, model, temperature, max_tokens
        )
        
        # å¿œç­”ã‚’éŸ³å£°ã«å¤‰æ›
        audio_response = self.audio_utils.text_to_speech(response)
        
        # å±¥æ­´ã‚’æ›´æ–°
        history.append((text, response))
        return history, history, audio_response
    
    def build_interface(self):
        """Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ§‹ç¯‰"""
        with gr.Blocks(title="Gemma3 æ—¥æœ¬èªéŸ³å£°ãƒãƒ£ãƒƒãƒˆ") as demo:
            gr.Markdown("# ğŸ¤– Gemma3 æ—¥æœ¬èªéŸ³å£°ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
            gr.Markdown("Ollamaã‚’ä½¿ç”¨ã—ã¦LLMã¨æ—¥æœ¬èªã§ä¼šè©±ã§ãã¾ã™ã€‚éŸ³å£°å…¥åŠ›ã¨éŸ³å£°å‡ºåŠ›ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚")

            with gr.Row():
                with gr.Column(scale=3):
                    chatbot = gr.Chatbot(label="ä¼šè©±", height=500)
                    
                    with gr.Row():
                        text_input = gr.Textbox(label="ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›", placeholder="ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...", lines=2)
                    
                    with gr.Row():
                        audio_input = gr.Audio(
                            label="éŸ³å£°ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›", 
                            type="filepath", 
                            source="microphone",
                            format="wav"
                        )
                    
                    with gr.Row():
                        audio_output = gr.Audio(label="AIã®å¿œç­”ï¼ˆéŸ³å£°ï¼‰", autoplay=True)
                    
                    with gr.Row():
                        clear_btn = gr.Button("ä¼šè©±ã‚’ã‚¯ãƒªã‚¢")
                    
                with gr.Column(scale=1):
                    available_models = self.ollama_service.get_available_models()
                    default_model = MODEL_NAME if MODEL_NAME in available_models else (available_models[0] if available_models else MODEL_NAME)
                    
                    model_dropdown = gr.Dropdown(
                        choices=available_models if available_models else [MODEL_NAME],
                        value=default_model,
                        label="ãƒ¢ãƒ‡ãƒ«é¸æŠ"
                    )
                    
                    temperature = gr.Slider(
                        minimum=0.0,
                        maximum=2.0,
                        value=DEFAULT_TEMPERATURE,
                        step=0.1,
                        label="Temperature"
                    )
                    
                    max_tokens = gr.Slider(
                        minimum=16,
                        maximum=4096,
                        value=DEFAULT_MAX_TOKENS,
                        step=16,
                        label="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
                    )
                    
                    gr.Markdown("### ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
                    if available_models:
                        gr.Markdown("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«:")
                        for model in available_models:
                            gr.Markdown(f"- `{model}`")
                    else:
                        gr.Markdown("**è­¦å‘Š**: Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ããªã„ã‹ã€ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        gr.Markdown("OllamaãŒå®Ÿè¡Œä¸­ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ã®è¨­å®š
            text_input.submit(
                self.chat, 
                [text_input, chatbot, temperature, max_tokens, model_dropdown], 
                [chatbot, chatbot, audio_output]
            ).then(lambda: "", None, [text_input])
            
            audio_input.change(
                self.voice_chat, 
                [audio_input, chatbot, temperature, max_tokens, model_dropdown], 
                [chatbot, chatbot, audio_output]
            )
            
            clear_btn.click(lambda: [], None, [chatbot])
            
            # ãƒ•ãƒƒã‚¿ãƒ¼
            gr.Markdown("---")
            gr.Markdown("*ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã®Ollamaã‚’ä½¿ç”¨ã—ã¦LLMã¨ä¼šè©±ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ã‚ãªãŸã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‹ã‚‰å¤–éƒ¨ã«é€ä¿¡ã•ã‚Œã¾ã›ã‚“ã€‚*")
        
        return demo 